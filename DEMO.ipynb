{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes: 10, edges: 8\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import Hazard\n",
    "from Utils.NetworkUtils import *\n",
    "from Utils.Plot import *\n",
    "from DynamicNetwork import DynamicNetwork\n",
    "from HazardMLE import *\n",
    "\n",
    "# Used to generate dynamic network\n",
    "start_date = int(time.mktime(datetime.datetime.strptime(\"08/16/2016\", \"%m/%d/%Y\").timetuple()))\n",
    "file = \"network_data/TheGoodPlace_sample.graphml\"   # The good place network\n",
    "WEEK_IN_SECOND = 7 * 24 * 60 * 60                   # Week in second\n",
    "HAZARD_BETA = [0.1, 0.1, 0.1]\n",
    "\n",
    "g = get_graphml(file)\n",
    "g = sample(g, 10/len(g))      # Get a small sample of network (10 nodes)   \n",
    "graph_info(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adoption Possibility 0.10000, got 0.21478, Not Adopted\nAdoption Possibility 0.10000, got 0.79843, Not Adopted\nAdoption Possibility 0.10000, got 0.49281, Not Adopted\nAdoption Possibility 0.10000, got 0.23249, Not Adopted\nAdoption Possibility 0.10000, got 0.41823, Not Adopted\nAdoption Possibility 0.10000, got 0.34055, Not Adopted\nAdoption Possibility 0.10000, got 0.36731, Not Adopted\nAdoption Possibility 0.10000, got 0.66949, Not Adopted\nAdoption Possibility 0.10000, got 0.22565, Not Adopted\nAdoption Possibility 0.10000, got 0.71367, Not Adopted\nAdoption Possibility 0.10000, got 0.64148, Not Adopted\nAdoption Possibility 0.10000, got 0.23146, Not Adopted\nAdoption Possibility 0.10000, got 0.53630, Not Adopted\nAdoption Possibility 0.10000, got 0.12659, Not Adopted\nAdoption Possibility 0.10000, got 0.79701, Not Adopted\nAdoption Possibility 0.10000, got 0.40655, Not Adopted\nAdoption Possibility 0.10000, got 0.46474, Not Adopted\nAdoption Possibility 0.10000, got 0.66852, Not Adopted\nAdoption Possibility 0.10000, got 0.05619, Adopted\nAdoption Possibility 0.10000, got 0.78670, Not Adopted\nAdoption Possibility 0.10000, got 0.11687, Not Adopted\nAdoption Possibility 0.10000, got 0.32993, Not Adopted\nAdoption Possibility 0.10000, got 0.31144, Not Adopted\nAdoption Possibility 0.10000, got 0.37660, Not Adopted\nAdoption Possibility 0.10000, got 0.43220, Not Adopted\nAdoption Possibility 0.10000, got 0.52262, Not Adopted\nAdoption Possibility 0.10000, got 0.87774, Not Adopted\nAdoption Possibility 0.22911, got 0.61634, Not Adopted\nAdoption Possibility 0.10000, got 0.99845, Not Adopted\nAdoption Possibility 0.10000, got 0.98980, Not Adopted\nAdoption Possibility 0.10000, got 0.08260, Adopted\nAdoption Possibility 0.10000, got 0.93284, Not Adopted\nAdoption Possibility 0.10000, got 0.09904, Adopted\nAdoption Possibility 0.10000, got 0.77289, Not Adopted\nAdoption Possibility 0.10000, got 0.15015, Not Adopted\nAdoption Possibility 0.10000, got 0.00545, Adopted\nAdoption Possibility 0.23276, got 0.43621, Not Adopted\nAdoption Possibility 0.10000, got 0.05956, Adopted\nAdoption Possibility 0.10000, got 0.32709, Not Adopted\nAdoption Possibility 0.10000, got 0.51122, Not Adopted\nAdoption Possibility 0.10000, got 0.03881, Adopted\nAdoption Possibility 0.10000, got 0.64698, Not Adopted\nAdoption Possibility 0.23449, got 0.19703, Adopted\nAdoption Possibility 0.10000, got 0.93959, Not Adopted\nAdoption Possibility 0.10000, got 0.49271, Not Adopted\nAdoption Possibility 0.10000, got 0.13652, Not Adopted\nAdoption Possibility 0.24520, got 0.26335, Not Adopted\nAdoption Possibility 0.17289, got 0.86322, Not Adopted\nAdoption Possibility 0.10000, got 0.47221, Not Adopted\nAdoption Possibility 0.11448, got 0.98669, Not Adopted\nAdoption Possibility 0.18228, got 0.93992, Not Adopted\nAdoption Possibility 0.10000, got 0.93610, Not Adopted\nAdoption Possibility 0.18412, got 0.58524, Not Adopted\nAdoption Possibility 0.29290, got 0.16914, Adopted\nAdoption Possibility 0.10000, got 0.31786, Not Adopted\nAdoption Possibility 0.21886, got 0.53339, Not Adopted\nAdoption Possibility 0.10000, got 0.40540, Not Adopted\nAdoption Possibility 0.13241, got 0.70294, Not Adopted\nAdoption Possibility 0.10000, got 0.16089, Not Adopted\nAdoption Possibility 0.23660, got 0.91759, Not Adopted\nAdoption Possibility 0.10000, got 0.59985, Not Adopted\nAdoption Possibility 0.12750, got 0.39537, Not Adopted\nAdoption Possibility 0.10000, got 0.97357, Not Adopted\nAdoption Possibility 0.25671, got 0.31812, Not Adopted\nAdoption Possibility 0.10000, got 0.70977, Not Adopted\nAdoption Possibility 0.12608, got 0.89994, Not Adopted\nAdoption Possibility 0.10000, got 0.39010, Not Adopted\nAdoption Possibility 0.19475, got 0.16520, Adopted\nAdoption Possibility 0.10000, got 0.59391, Not Adopted\nAdoption Possibility 0.10000, got 0.23573, Not Adopted\nAdoption Possibility 0.10000, got 0.41397, Not Adopted\nAdoption Possibility 0.10000, got 0.21479, Not Adopted\nAdoption Possibility 0.10000, got 0.53991, Not Adopted\nAdoption Possibility 0.10000, got 0.34005, Not Adopted\nAdoption Possibility 0.10000, got 0.26984, Not Adopted\nAdoption Possibility 0.26480, got 0.16855, Adopted\nAdopted users every week: [0, 1, 1, 5, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10], 23 steps.\n"
     ]
    }
   ],
   "source": [
    "g = DynamicNetwork(g)   \n",
    "# Hazard model simulation, using params [beta1, beta2, beta3] = [0.3, 0.3 ,0.3]\n",
    "model = Hazard.Hazard(g, start_date, WEEK_IN_SECOND, HAZARD_BETA)        \n",
    "ref_result, fake_data = model.hazard()\n",
    "print(\"Adopted users every week: {}, {} steps.\".format(ref_result, len(ref_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                NODEID     SECONDS  CONSTANT  ADOPTED_NEIGHBORS  SENTIMENT  ADOPTION\n0            146318194  1471330800         1                  0  -0.641097         0\n1            146318194  1471935600         1                  1  -0.004498         0\n2            146318194  1472540400         1                  2  -0.621756         0\n3            146318194  1473145200         1                  3   0.935530         0\n4            146318194  1473750000         1                  4  -0.754987         0\n5            146318194  1474354800         1                  5   0.684619         0\n6            146318194  1474959600         1                  6   0.452047         0\n7            146318194  1475564400         1                  7  -0.855246         0\n8            146318194  1476169200         1                  8  -0.158783         0\n9            146318194  1476774000         1                  9   0.188584         0\n10           146318194  1477378800         1                 10  -0.675940         0\n11           146318194  1477983600         1                 11   0.365975         0\n12           146318194  1478588400         1                 12  -0.725010         0\n13           146318194  1479193200         1                 13   0.567086         0\n14           146318194  1479798000         1                 14  -0.739230         0\n15           146318194  1480402800         1                 15  -0.052480         1\n16            18326476  1471330800         1                  0   0.538133         0\n17            18326476  1471935600         1                  1  -0.202828         0\n18            18326476  1472540400         1                  2   0.786525         0\n19            18326476  1473145200         1                  3   0.783668         1\n20           209344884  1471330800         1                  0   0.398426         0\n21           209344884  1471935600         1                  1   0.913140         0\n22           209344884  1472540400         1                  2   0.448862         0\n23           209344884  1473145200         1                  3   0.851050         0\n24           209344884  1473750000         1                  4  -0.058039         0\n25           209344884  1474354800         1                  5  -0.058930         0\n26           209344884  1474959600         1                  6  -0.271095         0\n27           209344884  1475564400         1                  7  -0.177190         0\n28           209344884  1476169200         1                  8   0.928979         1\n29          2702586091  1471330800         1                  0   0.079901         0\n30          2702586091  1471935600         1                  1   0.083064         0\n31          2702586091  1472540400         1                  2  -0.797083         0\n32          2702586091  1473145200         1                  3   0.014298         0\n33          2702586091  1473750000         1                  4  -0.008223         1\n34            28567268  1471330800         1                  0   0.239099         0\n35            28567268  1471935600         1                  1  -0.544459         0\n36            28567268  1472540400         1                  2  -0.226645         0\n37            28567268  1473145200         1                  3   0.096482         1\n38            37154598  1471330800         1                  0   0.538045         0\n39            37154598  1471935600         1                  1  -0.720718         0\n40            37154598  1472540400         1                  2   0.380908         0\n41            37154598  1473145200         1                  3  -0.576898         1\n42            51913277  1471330800         1                  0  -0.641686         0\n43            51913277  1471935600         1                  1   0.624839         1\n44            63547227  1471330800         1                  0   0.455745         0\n45            63547227  1471935600         1                  1  -0.133827         0\n46            63547227  1472540400         1                  2   0.291111         0\n47            63547227  1473145200         1                  3   0.327642         0\n48            63547227  1473750000         1                  4   0.344927         1\n49  727917066632585216  1471330800         1                  0  -0.192958         0\n50  727917066632585216  1471935600         1                  1  -0.439910         0\n51  727917066632585216  1472540400         1                  2   0.836502         0\n52  727917066632585216  1473145200         1                  3   0.192874         0\n53  727917066632585216  1473750000         1                  4   0.226033         0\n54  727917066632585216  1474354800         1                  5   0.986317         0\n55  727917066632585216  1474959600         1                  6   0.378780         0\n56  727917066632585216  1475564400         1                  7   0.193076         0\n57  727917066632585216  1476169200         1                  8   0.394533         0\n58  727917066632585216  1476774000         1                  9  -0.425569         0\n59  727917066632585216  1477378800         1                 10  -0.432540         0\n60  727917066632585216  1477983600         1                 11   0.141100         0\n61  727917066632585216  1478588400         1                 12  -0.528642         0\n62  727917066632585216  1479193200         1                 13  -0.303141         0\n63  727917066632585216  1479798000         1                 14   0.406200         0\n64  727917066632585216  1480402800         1                 15   0.991895         0\n65  727917066632585216  1481007600         1                 16  -0.601052         0\n66  727917066632585216  1481612400         1                 17  -0.423873         0\n67  727917066632585216  1482217200         1                 18  -0.601931         0\n68  727917066632585216  1482822000         1                 19   0.548087         0\n69  727917066632585216  1483426800         1                 20  -0.558424         0\n70  727917066632585216  1484031600         1                 21   0.700375         0\n71  727917066632585216  1484636400         1                 22   0.647990         1\n72           937976042  1471330800         1                  0  -0.308071         0\n73           937976042  1471935600         1                  1  -0.197661         0\n74           937976042  1472540400         1                  2   0.752934         0\n75           937976042  1473145200         1                  3   0.748951         1\n"
     ]
    }
   ],
   "source": [
    "def fake_train_data(fake_data):\n",
    "    from pandas import DataFrame, Series\n",
    "    train_data_exog = []\n",
    "    train_data_endog = []\n",
    "    \n",
    "    # For demo only begin\n",
    "    for k, i in fake_data.items():\n",
    "        train_data_exog.append([k[0], k[1]] + [1] + list(i[1:]) + [i[0]])\n",
    "        train_data_endog.append(i[0])\n",
    "    train_data_exog.sort(key=lambda i: (i[0], i[1]))\n",
    "    train_data_exog = DataFrame(\n",
    "        train_data_exog, \n",
    "        columns=[\"NODEID\", \"SECONDS\", \"CONSTANT\", \"ADOPTED_NEIGHBORS\", \"SENTIMENT\", \"ADOPTION\"])\n",
    "    print(train_data_exog.to_string())\n",
    "    # For demo only end\n",
    "    #\n",
    "    \n",
    "    train_data_exog = []\n",
    "    train_data_endog = []\n",
    "    for k, i in fake_data.items():\n",
    "        train_data_exog.append([1] + list(i[1:]))\n",
    "        train_data_endog.append(i[0])\n",
    "    train_data_exog = DataFrame(train_data_exog, columns=[\"CONSTANT\", \"ADOPTED_NEIGHBORS\", \"SENTIMENT\"])\n",
    "    train_data_endog = Series(train_data_endog, name=\"ADOPTION\")\n",
    "\n",
    "    return train_data_exog, train_data_endog\n",
    "\n",
    "# Get exog and endog for mle\n",
    "exog, endog = fake_train_data(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta values [  1.00000000e-05   1.00000000e-05   7.32540455e-02]\n"
     ]
    }
   ],
   "source": [
    "result = HazardModel(exog=exog, endog=endog).fit(method=\"lbfgs\", bounds=[(0.00001, .999), (0.00001, .999), (0.00001, .999)])\n",
    "print(\"Beta values {}\".format(result.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE loglikelihood\n[  1.00000000e-05   1.00000000e-05   7.32540455e-02], -52.64501631744964\nOriginal loglikelihood\n[0.1, 0.1, 0.1], -104.63422007228706\n"
     ]
    }
   ],
   "source": [
    "def print_loglikelihood(exogs, endogs, params):\n",
    "    exogs = np.asarray(exogs)\n",
    "    endogs = np.asarray(endogs)\n",
    "\n",
    "    log_likelihood = 0\n",
    "\n",
    "    for exog, endog in zip(exogs, endogs):\n",
    "        if endog == 1:\n",
    "            log_likelihood += stats.norm.logcdf(np.dot(exog, params)).sum()\n",
    "        elif endog == 0:\n",
    "            log_likelihood += stats.norm.logcdf(-1 * np.dot(exog, params)).sum()\n",
    "        else:\n",
    "            assert False, \"Shouldn't run into this line\"\n",
    "\n",
    "    print(\"{}, {}\".format(params, log_likelihood))\n",
    "    \n",
    "# params = [round(p, 3) for p in result.params] # Reset params to 3 digits after decimal\n",
    "print(\"MLE loglikelihood\")\n",
    "print_loglikelihood(exog, endog, result.params)\n",
    "print(\"Original loglikelihood\")\n",
    "print_loglikelihood(exog, endog, HAZARD_BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}